# Generated by Django 3.0.3 on 2020-03-01 11:18

import io
import pickle
from os import mkdir
from os.path import join, exists

import numpy as np
from django.db import migrations

from hate_speech.settings import BASE_DIR, all_properties


class AbstractFeature:
    resources_folder = "resources"
    features_folder = "features"
    path_to_features = join(BASE_DIR, resources_folder, features_folder)

    def __init__(self):
        if not exists(self.path_to_features):
            mkdir(self.path_to_features)

    @staticmethod
    def write_to_pickle(vector, path):
        with open(path, "wb") as f:
            pickle.dump(vector, f)


class WordEmbeddings(AbstractFeature):
    embeddings_folder = "embeddings"

    def __init__(self):
        super().__init__()
        self.name = "embeddings"
        self.path_to_embeddings = join(BASE_DIR, self.resources_folder, self.features_folder, self.embeddings_folder)
        embeddings_properties = all_properties["features"]["embeddings"]
        self.embeddings = {}
        for embedding in embeddings_properties:
            self.embeddings[embedding["language"]] = embedding["file_name"]

    def create_embedding_features(self, Dataset, Tweet, Feature):
        for language, filename in self.embeddings.items():
            if language != "english":
                continue
            word_embeddings = self._load_vectors(language=language, filename=filename)
            datasets = Dataset.objects.filter(language=language)
            for dataset in datasets:
                dataset_path = join(self.path_to_embeddings, dataset)
                tweets = Tweet.objects.filter(dataset=dataset)
                all_vectors = {}
                for tweet in tweets:
                    vectors = []
                    words = tweet.preprocessed_text.split(" ")
                    for word in words:
                        if word in word_embeddings.keys():
                            vectors.append(word_embeddings[word])
                    vectors = np.asarray(vectors)
                    vectors = np.mean(vectors, axis=1)
                    all_vectors[tweet.id] = vectors
                feature = Feature()
                feature.name = self.name
                feature.dataset = dataset
                feature.folder_path = dataset_path
                feature.filename = "embeddings_{}.pickle".format(dataset.name)
                feature.save()
                self.write_to_pickle(all_vectors, join(dataset_path, feature.filename))

    def _load_vectors(self, language, filename):
        path_to_file = join(BASE_DIR, self.resources_folder, self.embeddings_folder, language, filename)
        fin = io.open(path_to_file, 'r', encoding='utf-8', newline='\n', errors='ignore')
        n, d = map(int, fin.readline().split())
        print("Loaded dataset has {} words and vectors with dimension {}".format(n, d))
        data = {}
        for line in fin:
            tokens = line.rstrip().split(' ')
            data[tokens[0]] = map(float, tokens[1:])
        return data


def generate_features(apps, schema_editor):
    Dataset = apps.get_model("hate_speech_detection", "Dataset")
    Tweet = apps.get_model("hate_speech_detection", "Tweet")
    Feature = apps.get_model("hate_speech_detection", "Feature")
    embeddings_feature = WordEmbeddings()
    embeddings_feature.create_embedding_features(Dataset=Dataset, Tweet=Tweet, Feature=Feature)


class Migration(migrations.Migration):
    dependencies = [
        ("hate_speech_detection", "0004_auto_save_eng_bow_features")
    ]

    operations = [
        migrations.RunPython(generate_features),
    ]
